{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e91612a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0    No_x       년   회차 수계 명  중권역 명      분류코드 구_조사구간 명  \\\n",
      "0         0.0  2804.0  2012.0  1.0   한강  남한강상류  1001G050       광하   \n",
      "1         1.0  2804.0  2012.0  1.0   한강  남한강상류  1001G050       광하   \n",
      "2         2.0  2804.0  2012.0  1.0   한강  남한강상류  1001G050       광하   \n",
      "3         3.0  2804.0  2012.0  1.0   한강  남한강상류  1001G050       광하   \n",
      "4         4.0  2804.0  2012.0  1.0   한강  남한강상류  1001G050       광하   \n",
      "\n",
      "                        학명      국명  ...  생물기준명칭  횟수  중복시증권역명 Unnamed: 8 label  \\\n",
      "0  Koreanomelania nodifila  염주알다슬기  ...     NaN NaN      NaN        NaN   1.0   \n",
      "1  Koreanomelania nodifila  염주알다슬기  ...     NaN NaN      NaN        NaN   1.0   \n",
      "2  Koreanomelania nodifila  염주알다슬기  ...     NaN NaN      NaN        NaN   1.0   \n",
      "3  Koreanomelania nodifila  염주알다슬기  ...     NaN NaN      NaN        NaN   1.0   \n",
      "4  Koreanomelania nodifila  염주알다슬기  ...     NaN NaN      NaN        NaN   1.0   \n",
      "\n",
      "   No  위도  경도 조사기관   주소  \n",
      "0 NaN NaN NaN  NaN  NaN  \n",
      "1 NaN NaN NaN  NaN  NaN  \n",
      "2 NaN NaN NaN  NaN  NaN  \n",
      "3 NaN NaN NaN  NaN  NaN  \n",
      "4 NaN NaN NaN  NaN  NaN  \n",
      "\n",
      "[5 rows x 95 columns]\n",
      "----------------------------------------------------\n",
      "\n",
      "\n",
      "Index(['Unnamed: 0', 'No_x', '년', '회차', '수계 명', '중권역 명', '분류코드', '구_조사구간 명',\n",
      "       '학명', '국명', '개체 수', '위도_x', '경도_x', '주소_x', '조사기관_x', '지점코드', '운영여부',\n",
      "       '대권역', '조사구간 명', '수질기준위도', '수질기준경도', 'No_y', ' 월', ' 채수 일자', ' 수계 명',\n",
      "       ' 중권역 명', ' 수심', '음이온계면활성제(ABS)', '유량', '안티몬(Sb)', '비소(As)', '바륨(Ba)',\n",
      "       '벤젠', '생물화학적산소요구량(BOD)', '사염화탄소', '카드뮴(Cd)', '클로로포름', '염소이온(Cl-)',\n",
      "       '클로로필-a(Chlorophyll-a)', '시안(CN)', '화학적산소요구량(COD)', '색도', '크롬(Cr)',\n",
      "       '6가크롬(Cr6+)', '구리(Cu)', '1,2,-다이클로로에탄', '다이클로로메탄', '다이에틸헥실프탈레이트(DEHP)',\n",
      "       '1,4-다이옥세인', '용존산소(DO)', '용존총질소(DTN)', '용존총인(DTP)', '전기전도도(EC)',\n",
      "       '분원성대장균군', '용해성 철(Fe)', '불소(F)', '헥사클로로벤젠', '포름알데히드', '수은(Hg)',\n",
      "       '용해성 망간(Mn)', '암모니아성 질소(NH3-N)', '노말헥산추출물질', '니켈(Ni)', '질산성질소(NO3-N)',\n",
      "       '유기인', '납(Pb)', '폴리클로리네이티드비페닐(PCB)', '테트라클로로에틸렌(PCE)', '수소이온농도(pH)',\n",
      "       '페놀류(phenols)', '인산염 인(PO4-P)', '셀레늄(Se)', '부유물질(SS)', '트리클로로에틸렌(TCE)',\n",
      "       '총대장균군', '수온', '총질소(T-N)', '총유기탄소(TOC)', '총인(T-P)', '투명도', '아연(Zn)',\n",
      "       '위도_y', '경도_y', '조사기관_y', '주소_y', '생물기준명칭', '횟수', '중복시증권역명',\n",
      "       'Unnamed: 8', 'label', 'No', '위도', '경도', '조사기관', '주소'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "Potzrest = pd.read_csv(\"YJ_potz_rest2022 (1).csv\")\n",
    "\n",
    "# Now you can work with the data in the DataFrame\n",
    "# For example, you can print the first few rows of the DataFrame\n",
    "print(Potzrest.head())\n",
    "print(\"----------------------------------------------------\")\n",
    "print('\\n')\n",
    "print(Potzrest.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c716533",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'column'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mPotzrest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda_download\\lib\\site-packages\\pandas\\core\\generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5896\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5897\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5898\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5899\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5900\u001b[0m ):\n\u001b[0;32m   5901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'column'"
     ]
    }
   ],
   "source": [
    "print(Potzrest.column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c167338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the percentage of missing values in each column\n",
    "# missing_percentages = Potzrest.isnull().mean() * 100\n",
    "\n",
    "# # Filter the columns where the missing percentage is greater than 20%\n",
    "# columns_to_drop = missing_percentages[missing_percentages > 20].index\n",
    "# # Drop the selected columns from the DataFrame\n",
    "\n",
    "# Potzrest_dropped = Potzrest.drop(columns=columns_to_drop)\n",
    "\n",
    "# print(Potzrest_dropped.columns)\n",
    "\n",
    "# Potzrest_dropped = Potzrest_dropped.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f770b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['No_x', '수계 명', '중권역 명', '분류코드', '구_조사구간 명', '학명', '국명', '개체 수', '위도_x',\n",
      "       '경도_x', '주소_x', '조사기관_x', '지점코드', '운영여부', '대권역', '수질기준위도', '수질기준경도',\n",
      "       'No_y', ' 수심', '음이온계면활성제(ABS)', '유량', '안티몬(Sb)', '비소(As)', '바륨(Ba)',\n",
      "       '벤젠', '생물화학적산소요구량(BOD)', '사염화탄소', '카드뮴(Cd)', '클로로포름', '염소이온(Cl-)',\n",
      "       '클로로필-a(Chlorophyll-a)', '시안(CN)', '화학적산소요구량(COD)', '색도', '크롬(Cr)',\n",
      "       '6가크롬(Cr6+)', '구리(Cu)', '1,2,-다이클로로에탄', '다이클로로메탄', '다이에틸헥실프탈레이트(DEHP)',\n",
      "       '1,4-다이옥세인', '용존산소(DO)', '용존총질소(DTN)', '용존총인(DTP)', '전기전도도(EC)',\n",
      "       '분원성대장균군', '용해성 철(Fe)', '불소(F)', '헥사클로로벤젠', '포름알데히드', '수은(Hg)',\n",
      "       '용해성 망간(Mn)', '암모니아성 질소(NH3-N)', '노말헥산추출물질', '니켈(Ni)', '질산성질소(NO3-N)',\n",
      "       '유기인', '납(Pb)', '폴리클로리네이티드비페닐(PCB)', '테트라클로로에틸렌(PCE)', '수소이온농도(pH)',\n",
      "       '페놀류(phenols)', '인산염 인(PO4-P)', '셀레늄(Se)', '부유물질(SS)', '트리클로로에틸렌(TCE)',\n",
      "       '총대장균군', '수온', '총질소(T-N)', '총유기탄소(TOC)', '총인(T-P)', '투명도', '아연(Zn)',\n",
      "       '위도_y', '경도_y', '조사기관_y', '주소_y', '생물기준명칭', '횟수', '중복시증권역명',\n",
      "       'Unnamed: 8', 'label', 'No', '위도', '경도', '조사기관', '주소'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['Unnamed: 0', '년', '회차', '조사구간 명', ' 월', ' 채수 일자', ' 수계 명', ' 중권역 명']  # Specify the columns to drop\n",
    "\n",
    "\n",
    "data_frame_dropped = Potzrest.drop(columns=columns_to_drop)\n",
    "\n",
    "print(data_frame_dropped.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34bfce7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingDataError",
     "evalue": "exog contains inf or nans",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMissingDataError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m x \u001b[38;5;241m=\u001b[39m data_frame_dropped[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m생물화학적산소요구량(BOD)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m화학적산소요구량(COD)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m용존산소(DO)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m전기전도도(EC)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m수소이온농도(pH)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m부유물질(SS)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m수온\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m총질소(T-N)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m총인(T-P)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m 수심\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      6\u001b[0m x \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39madd_constant(x)\n\u001b[1;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOLS\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m     10\u001b[0m p_values \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpvalues\n\u001b[0;32m     12\u001b[0m significant_columns \u001b[38;5;241m=\u001b[39m p_values[p_values \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.05\u001b[39m]\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32m~\\anaconda_download\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:906\u001b[0m, in \u001b[0;36mOLS.__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    903\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeights are not supported in OLS and will be ignored\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    904\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn exception will be raised in the next version.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    905\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg, ValueWarning)\n\u001b[1;32m--> 906\u001b[0m \u001b[38;5;28msuper\u001b[39m(OLS, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, missing\u001b[38;5;241m=\u001b[39mmissing,\n\u001b[0;32m    907\u001b[0m                           hasconst\u001b[38;5;241m=\u001b[39mhasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_keys:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_keys\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda_download\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:733\u001b[0m, in \u001b[0;36mWLS.__init__\u001b[1;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     weights \u001b[38;5;241m=\u001b[39m weights\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m--> 733\u001b[0m \u001b[38;5;28msuper\u001b[39m(WLS, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, missing\u001b[38;5;241m=\u001b[39mmissing,\n\u001b[0;32m    734\u001b[0m                           weights\u001b[38;5;241m=\u001b[39mweights, hasconst\u001b[38;5;241m=\u001b[39mhasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    735\u001b[0m nobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    736\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights\n",
      "File \u001b[1;32m~\\anaconda_download\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:190\u001b[0m, in \u001b[0;36mRegressionModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28msuper\u001b[39m(RegressionModel, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_attr\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpinv_wexog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwendog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwexog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda_download\\lib\\site-packages\\statsmodels\\base\\model.py:267\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 267\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n",
      "File \u001b[1;32m~\\anaconda_download\\lib\\site-packages\\statsmodels\\base\\model.py:92\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m missing \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     91\u001b[0m hasconst \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhasconst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m---> 92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_data(endog, exog, missing, hasconst,\n\u001b[0;32m     93\u001b[0m                               \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mk_constant\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexog\n",
      "File \u001b[1;32m~\\anaconda_download\\lib\\site-packages\\statsmodels\\base\\model.py:132\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 132\u001b[0m     data \u001b[38;5;241m=\u001b[39m handle_data(endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[1;32m~\\anaconda_download\\lib\\site-packages\\statsmodels\\base\\data.py:700\u001b[0m, in \u001b[0;36mhandle_data\u001b[1;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    697\u001b[0m     exog \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[0;32m    699\u001b[0m klass \u001b[38;5;241m=\u001b[39m handle_data_class_factory(endog, exog)\n\u001b[1;32m--> 700\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m klass(endog, exog\u001b[38;5;241m=\u001b[39mexog, missing\u001b[38;5;241m=\u001b[39mmissing, hasconst\u001b[38;5;241m=\u001b[39mhasconst,\n\u001b[0;32m    701\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda_download\\lib\\site-packages\\statsmodels\\base\\data.py:88\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconst_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_constant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity()\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\anaconda_download\\lib\\site-packages\\statsmodels\\base\\data.py:134\u001b[0m, in \u001b[0;36mModelData._handle_constant\u001b[1;34m(self, hasconst)\u001b[0m\n\u001b[0;32m    132\u001b[0m exog_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(exog_max)\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingDataError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexog contains inf or nans\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    135\u001b[0m exog_min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    136\u001b[0m const_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(exog_max \u001b[38;5;241m==\u001b[39m exog_min)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "\u001b[1;31mMissingDataError\u001b[0m: exog contains inf or nans"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "y = data_frame_dropped['label']\n",
    "x = data_frame_dropped[['생물화학적산소요구량(BOD)', '화학적산소요구량(COD)', '용존산소(DO)', '전기전도도(EC)',\n",
    "       '수소이온농도(pH)', '부유물질(SS)', '수온', '총질소(T-N)', '총인(T-P)', ' 수심']]\n",
    "x = sm.add_constant(x)\n",
    "\n",
    "model = sm.OLS(y, x).fit()\n",
    "\n",
    "p_values = model.pvalues\n",
    "\n",
    "significant_columns = p_values[p_values < 0.05].index.tolist()\n",
    "\n",
    "print(significant_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb93167",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_frame_dropped[['수온', '용존산소(DO)','생물화학적산소요구량(BOD)', ' 수심']]\n",
    "print(x)\n",
    "# #사용하고 싶은 데이터만 잘라서 사용하고 싶을떄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3abaa162",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got [ 0.  1. nan]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Fit the model on the training data\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Make predictions on the test data\u001b[39;00m\n\u001b[0;32m     16\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\anaconda_download\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda_download\\lib\\site-packages\\xgboost\\sklearn.py:1440\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1435\u001b[0m     expected_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_)\n\u001b[0;32m   1436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1437\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m expected_classes\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1438\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m==\u001b[39m expected_classes)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m   1439\u001b[0m ):\n\u001b[1;32m-> 1440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1441\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1442\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1443\u001b[0m     )\n\u001b[0;32m   1445\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got [ 0.  1. nan]"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, brier_score_loss, cohen_kappa_score\n",
    "\n",
    "# Assuming you have your features in a DataFrame named 'X' and the corresponding labels in a Series named 'y'\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "brier_score = brier_score_loss(y_test, y_pred)\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"AUC:\", auc)\n",
    "print(\"Brier Score:\", brier_score)\n",
    "print(\"Kappa:\", kappa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70cfe77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Combination: ('생물화학적산소요구량(BOD)', '화학적산소요구량(COD)', '전기전도도(EC)', '수온', '총질소(T-N)')\n",
      "Best Accuracy: 0.7368421052631579\n",
      "Best Precision: 0.803921568627451\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, brier_score_loss, cohen_kappa_score\n",
    "import itertools\n",
    "\n",
    "# Define the features to consider\n",
    "features = ['생물화학적산소요구량(BOD)', '화학적산소요구량(COD)', '용존산소(DO)', '전기전도도(EC)', '수소이온농도(pH)', '부유물질(SS)', '수온', '총질소(T-N)', '총인(T-P)']\n",
    "\n",
    "best_accuracy = 0.0\n",
    "best_precision = 0.0\n",
    "best_feature_combination = []\n",
    "\n",
    "# Iterate through different feature combinations\n",
    "for r in range(1, len(features) + 1):\n",
    "    for subset in itertools.combinations(features, r):\n",
    "        # Extract the selected features\n",
    "        x = data_frame_dropped[list(subset)]\n",
    "        y = data_frame_dropped['label']\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "        # Initialize the XGBoost classifier\n",
    "        model = xgb.XGBClassifier()\n",
    "\n",
    "        # Fit the model on the training data\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Compute accuracy and precision scores\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "\n",
    "#         # Check if the current combination outperforms the previous best\n",
    "#         if accuracy > best_accuracy and precision > best_precision:\n",
    "#             best_accuracy = accuracy\n",
    "#             best_precision = precision\n",
    "#             best_feature_combination = subset\n",
    "\n",
    "        # Check if the current combination outperforms the previous best\n",
    "        if  precision > best_precision:\n",
    "            best_accuracy = accuracy\n",
    "            best_precision = precision\n",
    "            best_feature_combination = subset\n",
    "\n",
    "# Print the best feature combination and its corresponding accuracy and precision scores\n",
    "print(\"Best Feature Combination:\", best_feature_combination)\n",
    "print(\"Best Accuracy:\", best_accuracy)\n",
    "print(\"Best Precision:\", best_precision) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce162641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision\n",
    "# '생물화학적산소요구량(BOD)', '화학적산소요구량(COD)', '전기전도도(EC)', '수온', '총질소(T-N)'\n",
    "# Best Accuracy: 0.7368421052631579\n",
    "# Best Precision: 0.803921568627451\n",
    "\n",
    "# accuracy\n",
    "# '생물화학적산소요구량(BOD)', '화학적산소요구량(COD)', '용존산소(DO)', '수소이온농도(pH)', '부유물질(SS)', '총인(T-P)'\n",
    "# Best Accuracy: 0.7719298245614035\n",
    "# Best Precision: 0.7777777777777778\n",
    "\n",
    "# whole\n",
    "# '생물화학적산소요구량(BOD)', '화학적산소요구량(COD)', '전기전도도(EC)', '총질소(T-N)', '총인(T-P)'\n",
    "# Best Accuracy: 0.7631578947368421\n",
    "# Best Precision: 0.7833333333333333        ㅏ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
